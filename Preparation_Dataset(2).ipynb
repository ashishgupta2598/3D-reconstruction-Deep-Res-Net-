{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Preparation Dataset.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z3JGHYfDo60m",
        "colab_type": "text"
      },
      "source": [
        "#DataSet\n",
        "DataSet is taken from 3D R2N2 Research Paper. \\\n",
        "Datasets\n",
        "They used ShapeNet models to generate rendered images and voxelized models. Links are available below.\\\n",
        "ShapeNet rendered images http://cvgl.stanford.edu/data2/ShapeNetRendering.tgz \\\n",
        "ShapeNet voxelized models http://cvgl.stanford.edu/data2/ShapeNetVox32.tgz"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NJRbwLqbFrLv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Here now list 2 contanins name of all the folder images:\n",
        "\n",
        "\n",
        "def DataRead(path):\n",
        "    list2={}\n",
        "    dict1={}\n",
        "    list1=[]\n",
        "    ak=os.listdir(path)#All direcories in the given folder whose path is given\n",
        "    for i in range(len(ak)):\n",
        "        pk=os.path.join(path,ak[i])#Join the main Path with the files present in \n",
        "        list1.append(pk)           #it\n",
        "    for i in range(len(list1)):#now explore pk and find all files in each  \n",
        "        ak=os.listdir(list1[i])#directories\n",
        "        for j in range(len(ak)):\n",
        "            pk=os.path.join(list1[i],ak[j])#Finally explore the image contaning \n",
        "                                           #dir\n",
        "            \n",
        "            dict1.update({j:pk})#j,pk because a type of specific object\n",
        "                                #(Like any specific car)  with its images as pk\n",
        "        list2.update({i:dict1})#I created dictionary with \n",
        "                                #i as (class like car,airplane) as key so path \n",
        "                                #to access it easily.  \n",
        "        dict1={}\n",
        "    \n",
        "    return list2       \n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qZ2z3HAbFrL1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#NOW list1 contains all the name of files\n",
        "#Eg---'F:\\\\SProject\\\\ShapeNetRendering\\\\02691156',\n",
        "#imges(only images)-----\n",
        "import torch\n",
        "#only 4 sets are taken\n",
        "\n",
        "#Tensor 4*100*24----4 classes(like chair,etc) with 100 different objects and \n",
        "#each object with 24 objects\n",
        "arr=torch.empty([4,100,24,3,128,128])\n",
        "path1=r\"/content/New folder\"\n",
        "list1=DataRead(path1)\n",
        "for i in range(4):#(len(list1)):\n",
        "    print(i)\n",
        "    for j in range(100):#(len(list1[i])):\n",
        "        #rendering.txt contains names of images in png format  \n",
        "        nm=os.path.join(list1[i][j],\"rendering/renderings.txt\")\n",
        "        #print(nm)\n",
        "          \n",
        "\n",
        "        pl=pd.read_csv(nm,names=[0])\n",
        "        for k in range(len(pl)):\n",
        "            #Here we are at the last directories and  images names are joined with it\n",
        "            img=Image.open(os.path.join(list1[i][j],\"rendering\",pl[0][k])).convert(\"RGB\")\n",
        "            \n",
        "            im=transform(img)\n",
        "            arr[i][j][k]=im\n",
        "        "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q5YEre21usKU",
        "colab_type": "text"
      },
      "source": [
        "#Binvox"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pYIgeakqusOs",
        "colab_type": "text"
      },
      "source": [
        "We have our 3D models in the form of .binox files. So for the conversion to binary voxel array we have Python module binvox-rw-py. \\\n",
        "Attaches the link--\n",
        "https://github.com/dimatura/binvox-rw-py"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i3pDd70UFrMF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import binvox_rw\n",
        "def read_3D(an):\n",
        "    with open(an, 'rb') as f:\n",
        "        model = binvox_rw.read_as_3d_array(f)\n",
        "        m=model.data \n",
        "        return m.astype(int)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xlBohdTcKG5R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WFe5n2mDFrMJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Now 3D models reading\n",
        "trans3D=transforms.ToTensor()\n",
        "path2=\"r/content/ShapeNetVox32\"#Directories where i stored  ShapeNetVox32\n",
        "arr_3D=torch.empty([4,100,32,32,32])\n",
        "list2=DataRead(path2)\n",
        "for i in range(5):#(len(list2)):\n",
        "    \n",
        "    for j in range(100):#(len(list2[i])):\n",
        "        an=os.path.join(list2[i][j],'model.binvox')#Path to dir where 3D model\n",
        "        ap=trans3D(read_3D(an))                    #is present\n",
        "        arr_3D[i][j]=ap\n",
        "                                                                            \n",
        "                \n",
        "arr_3D=arr_3D.view(4,100,1,32,32,32)        \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4xJ7l3BLFrMN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "path2=r\"/content/ShapeNetVox32\"\n",
        "list2=DataRead(path2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ht9XdQO-FrMQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H9YvAtF742bV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "####TESTING PURPOSE#######IGONE IT\n",
        "arr_m=torch.empty(100,1,2,32,32,32)\n",
        "for i in range(100):\n",
        "  for j in range(32):\n",
        "    for k in range(32):\n",
        "      for l in range(32):\n",
        "        arr_m[i][0][0][j][k][l]=0\n",
        "        if arr_3d[i][0][j][k][l]==0:\n",
        "            arr_m[i][0][1][j][k][l]=0\n",
        "        elif arr_3d[i][0][j][k][l]==1:\n",
        "            arr_m[i][0][1][j][k][l]=1\n",
        "        else:\n",
        "          print(\"i\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tUTWoBE_FrMR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4iAk4rLOFrMh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_-CIhGhoFrMk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GV1QZLP3FrMm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oRh7hpF9FrMv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e83btHPAFrMy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FXjjSQPAFrM1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dnQnXcs6FrM7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "29ePav4po5qr",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    }
  ]
}